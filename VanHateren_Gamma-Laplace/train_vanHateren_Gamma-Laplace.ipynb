{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/'.join(os.getcwd().split('/')[:-1])\n",
    "methods_dir = f'{ROOT_PATH}/Methods/VanHateren_Gamma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(methods_dir)\n",
    "from methods import CsikorDataset, Laplace_FC_VAE, Gamma_free_Laplace_FC_VAE, set_seed, train_and_val, z_train_and_val, replace_point_by_underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2 has been set.\n"
     ]
    }
   ],
   "source": [
    "natural40_dir = f'{ROOT_PATH}/Datasets/VanHateren/'\n",
    "\n",
    "train_labels = pkl.load(open(natural40_dir+'train_labels.pkl','rb'))\n",
    "len_trainset = len(train_labels)\n",
    "\n",
    "train_images = np.load(natural40_dir+'train_images/train_images.npy').astype(np.float32)\n",
    "\n",
    "n_data = len(train_images)\n",
    "perc_val = 0.2\n",
    "\n",
    "# generating subset based on indices\n",
    "set_seed(seed=2, seed_torch=True)\n",
    "\n",
    "import_idxs = True\n",
    "\n",
    "if import_idxs:\n",
    "    train_idxs = np.load(natural40_dir+'train_idxs.npy')\n",
    "    val_idxs = np.load(natural40_dir+'val_idxs.npy')\n",
    "\n",
    "else:\n",
    "    train_idxs, val_idxs = train_test_split(\n",
    "        range(n_data),\n",
    "        test_size=perc_val\n",
    "    )\n",
    "    np.save(natural40_dir+'train_idxs.npy',train_idxs)\n",
    "    np.save(natural40_dir+'val_idxs.npy',val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will rescale images to 0-1\n",
      "Will remove mean from images\n"
     ]
    }
   ],
   "source": [
    "rescale_0_1 = True\n",
    "remove_mean = True\n",
    "\n",
    "if rescale_0_1:\n",
    "    compute_pix_mean_std = False\n",
    "    if compute_pix_mean_std:   \n",
    "        nat_train_pixs_mean = train_images[train_idxs].mean()\n",
    "        nat_train_pixs_std = train_images[train_idxs].std()\n",
    "        np.save(natural40_dir+'nat_train_pixs_mean.npy',nat_train_pixs_mean)\n",
    "        np.save(natural40_dir+'nat_train_pixs_std.npy',nat_train_pixs_std)\n",
    "    else:\n",
    "        nat_train_pixs_mean = np.load(natural40_dir+'nat_train_pixs_mean.npy')\n",
    "        nat_train_pixs_std = np.load(natural40_dir+'nat_train_pixs_std.npy')    \n",
    "    print('Will rescale images to 0-1')\n",
    "    train_images_ = (train_images - nat_train_pixs_mean)/(6*nat_train_pixs_std)+1/2\n",
    "        \n",
    "    if remove_mean:\n",
    "        print('Will remove mean from images')\n",
    "        train_images__ = train_images_ - np.mean(train_images_,axis=(1),keepdims=True)\n",
    "\n",
    "        nat_dataset = CsikorDataset(train_labels,train_images__)\n",
    "    else:\n",
    "        nat_dataset = CsikorDataset(train_labels,train_images_)\n",
    "else:\n",
    "    nat_dataset = CsikorDataset(train_labels,train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train, validation and test sets: 512000, 128000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataset = Subset(nat_dataset,train_idxs)\n",
    "val_dataset = Subset(nat_dataset,val_idxs)\n",
    "\n",
    "n_train = len(train_dataset)\n",
    "n_val = len(val_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'length train, validation and test sets: {n_train}, {n_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your models' hyperparameters (shown here manuscript values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model parameters\n",
    "latent_dim_vae = 1800\n",
    "latent_dim_eavae = 1799\n",
    "imsize = 1600 #Fixed\n",
    "variational_beta_y_vae = .015\n",
    "variational_beta_y_eavae = .015\n",
    "variational_beta_z_eavae = .03\n",
    "k_param = 2\n",
    "theta_param = float(1/np.sqrt(2))\n",
    "learning_rate = 3e-5\n",
    "weight_decay = 1e-5\n",
    "nepochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize VAE and EA-VAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if torch.cuda is available\n",
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "uncomp_model_vae = Laplace_FC_VAE(n_train,n_val,latent_dim_vae,imsize,learning_rate,weight_decay, device=device)\n",
    "uncomp_model_eavae = Gamma_free_Laplace_FC_VAE(n_train,n_val,latent_dim_eavae,imsize,learning_rate,weight_decay,k_param,theta_param, device=device)\n",
    "\n",
    "model_vae = uncomp_model_vae\n",
    "model_vae = model_vae.to(device)\n",
    "\n",
    "model_eavae = uncomp_model_eavae\n",
    "model_eavae = model_eavae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory where models will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a directory to save the results\n",
    "out_location_vae = f'{ROOT_PATH}/VanHateren_Gamma-Laplace/Model_checkpoints/personal/latent_dim_{latent_dim_vae}/VAE/beta_y_'+replace_point_by_underscore(str(variational_beta_y_vae))+'/lr_'+replace_point_by_underscore(str(learning_rate))+'/'\n",
    "\n",
    "if not os.path.exists(out_location_vae):\n",
    "   os.makedirs(out_location_vae)\n",
    "   print(\"The directory was generated: \", out_location_vae)\n",
    "   \n",
    "out_location_eavae = f'{ROOT_PATH}/VanHateren_Gamma-Laplace/Model_checkpoints/personal/latent_dim_{latent_dim_eavae}/EA-VAE/beta_y_'+replace_point_by_underscore(str(variational_beta_y_eavae))+'/beta_z_'+replace_point_by_underscore(str(variational_beta_z_eavae))+'/lr_'+replace_point_by_underscore(str(learning_rate))+'/'\n",
    "\n",
    "if not os.path.exists(out_location_eavae):\n",
    "   os.makedirs(out_location_eavae)\n",
    "   print(\"The directory was generated: \", out_location_eavae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE (around 75 hr to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN VAE\n",
    "train_and_val(model_vae,train_dataloader,validation_dataloader, nepochs, variational_beta_y_vae, saving_path = out_location_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EA-VAE (around 75 hr to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN EA-VAE\n",
    "z_train_and_val(model_eavae, train_dataloader, validation_dataloader, nepochs, variational_beta_y_eavae, variational_beta_z_eavae, saving_path = out_location_eavae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
