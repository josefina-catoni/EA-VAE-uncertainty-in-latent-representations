{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from auxiliary_functions import remove_mean_transform, scale_0_1_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/'.join(os.getcwd().split('/')[:-1])\n",
    "data_dir = f'{ROOT_PATH}/Datasets/Mnist/'\n",
    "methods_dir = f'{ROOT_PATH}/Methods/MNIST_domains/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(methods_dir)\n",
    "from methods import VariationalAutoencoder,z_VariationalAutoencoder, set_seed, train_and_val, z_train_and_val, replace_point_by_underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mean = False\n",
    "scale_0_1 = False\n",
    "\n",
    "if remove_mean:\n",
    "    img_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: remove_mean_transform(x)) \n",
    "    ])\n",
    "elif scale_0_1:\n",
    "    img_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: scale_0_1_transform(x)) \n",
    "    ])\n",
    "else:\n",
    "    img_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),  \n",
    "    ])\n",
    "    \n",
    "dataset = MNIST(root=data_dir+'MNIST', download=True, train=True, transform=img_transform)\n",
    "#test_dataset = MNIST(root=data_dir+'MNIST', download=True, train=False, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2 has been set.\n",
      "length train, validation and test sets: 48000, 12000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "n_data = len(dataset)\n",
    "perc_val = 0.2\n",
    "\n",
    "# generating subset based on indices\n",
    "set_seed(seed=2, seed_torch=True)\n",
    "\n",
    "import_idxs = True\n",
    "\n",
    "if import_idxs:\n",
    "    train_idxs = np.load(data_dir+'train_idxs.npy')\n",
    "    val_idxs = np.load(data_dir+'val_idxs.npy')\n",
    "\n",
    "else:\n",
    "    train_idxs, val_idxs, _, _ = train_test_split(\n",
    "        range(n_data),\n",
    "        dataset.targets,\n",
    "        stratify=dataset.targets,\n",
    "        test_size=perc_val\n",
    "    )\n",
    "    np.save(data_dir+'train_idxs.npy',train_idxs)\n",
    "    np.save(data_dir+'val_idxs.npy',val_idxs)\n",
    "\n",
    "train_dataset = Subset(dataset,train_idxs)\n",
    "val_dataset = Subset(dataset,val_idxs)\n",
    "\n",
    "n_train = len(train_dataset)\n",
    "n_val = len(val_dataset)\n",
    "#n_test = len(test_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'length train, validation and test sets: {n_train}, {n_val}')#, {n_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your models' hyperparameters (shown here manuscript values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 32*32\n",
    "\n",
    "latent_dim_vae = 5\n",
    "latent_dim_eavae = 4\n",
    "\n",
    "variational_beta_y_vae = 4\n",
    "variational_beta_y_eavae = 4\n",
    "variational_beta_z_eavae = 1\n",
    "\n",
    "capacity = 64\n",
    "learning_rate = 1e-3\n",
    "nepochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize VAE and EA-VAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "uncomp_model_eavae = z_VariationalAutoencoder(n_train,n_val,input_dim,latent_dim_eavae,capacity,learning_rate,rec_loss_method='BCE', device=device)\n",
    "uncomp_model_vae = VariationalAutoencoder(n_train,n_val,input_dim,latent_dim_vae,capacity,learning_rate,rec_loss_method='BCE', device=device)\n",
    "'''\n",
    "if hasattr(torch, 'compile'):\n",
    "    print('torch.compile is available, will compile the model')\n",
    "    model = torch.compile(uncomp_model)\n",
    "else:\n",
    "    print('torch.compile is not available')\n",
    "    model = uncomp_model\n",
    "'''\n",
    "model_vae = uncomp_model_vae\n",
    "model_vae = model_vae.to(device)\n",
    "\n",
    "model_eavae = uncomp_model_eavae\n",
    "model_eavae = model_eavae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory where models will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a directory to save the results\n",
    "out_location_vae = f'{ROOT_PATH}/MNIST/Model_checkpoints/personal/latent_dim_{latent_dim_vae}/VAE/beta_y_'+replace_point_by_underscore(str(variational_beta_y_vae))+'/lr_'+replace_point_by_underscore(str(learning_rate))+'/'\n",
    "\n",
    "if not os.path.exists(out_location_vae):\n",
    "   os.makedirs(out_location_vae)\n",
    "   print(\"The directory was generated: \", out_location_vae)\n",
    "   \n",
    "out_location_eavae = f'{ROOT_PATH}/MNIST/Model_checkpoints/personal/latent_dim_{latent_dim_eavae}/EA-VAE/beta_y_'+replace_point_by_underscore(str(variational_beta_y_eavae))+'/beta_z_'+replace_point_by_underscore(str(variational_beta_z_eavae))+'/lr_'+replace_point_by_underscore(str(learning_rate))+'/'\n",
    "\n",
    "if not os.path.exists(out_location_eavae):\n",
    "   os.makedirs(out_location_eavae)\n",
    "   print(\"The directory was generated: \", out_location_eavae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE (around 1 hr to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN VAE\n",
    "train_and_val(model_vae,train_dataloader,validation_dataloader, nepochs, variational_beta_y_vae, saving_path = out_location_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EA-VAE (around 1 hr to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN EA-VAE\n",
    "z_train_and_val(model_eavae, train_dataloader, validation_dataloader, nepochs, variational_beta_y_eavae, variational_beta_z_eavae, saving_path= out_location_eavae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
